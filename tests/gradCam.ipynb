{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4872978",
   "metadata": {},
   "source": [
    "# GRADCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1e8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these are imported\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image as keras_image # Use alias to avoid conflict\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess_input # Or your model's specific preprocess\n",
    "import cv2 # Optional, but often convenient for resizing. Install with: pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    # Basic parameters\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"IM_SIZE\": 224,\n",
    "    \"NUM_CLASSES\": 4,\n",
    "    \"CLASS_NAMES\": [\"Fibres\", \"Nanowires\", \"Particles\",\"Powder\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb333982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"])):\n",
    "    \"\"\"Loads and preprocesses an image for the model.\"\"\"\n",
    "    img = keras_image.load_img(img_path, target_size=target_size)\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension\n",
    "    # Use the specific preprocessing function for your base model\n",
    "    # For EfficientNet:\n",
    "    processed_img = efficientnet_preprocess_input(img_array)\n",
    "    # For ResNet50: from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "    # processed_img = resnet50_preprocess_input(img_array)\n",
    "    # If you only did rescaling during training (like 1./255):\n",
    "    # processed_img = img_array / 255.0\n",
    "    return processed_img\n",
    "\n",
    "def deprocess_image_for_display(img_array):\n",
    "    \"\"\"Deprocesses image array for display (undoes scaling).\"\"\"\n",
    "    # If you used standard preprocess_input (scales to -1 to 1 or similar):\n",
    "    # This might need adjustment based on the exact preprocessing used.\n",
    "    # A simple approach is to scale back to 0-255 assuming initial scaling.\n",
    "    img_array = img_array.copy()\n",
    "    if np.max(img_array) <= 1.0 and np.min(img_array) >= -1.0: # Heuristic check\n",
    "        img_array = ((img_array + 1.0) * 127.5).astype(np.uint8) # Scale back from -1..1\n",
    "    elif np.max(img_array) <= 1.0 and np.min(img_array) >= 0.0: # Heuristic check for 0..1\n",
    "         img_array = (img_array * 255.0).astype(np.uint8)\n",
    "    return img_array.squeeze() # Remove batch dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generates the Grad-CAM heatmap.\"\"\"\n",
    "    # Create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute the gradient of the top predicted class (or specified class)\n",
    "    # for our input image with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Gradient of the output neuron (top predicted or chosen) w.r.t. the output feature map\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Vector of mean intensity of the gradient over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map array by \"how important this channel is\"\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization, normalize the heatmap between 0 & 1 and apply ReLU\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gradcam(img_path, heatmap, alpha=0.6, target_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"])):\n",
    "    \"\"\"Displays the heatmap superimposed on the original image.\"\"\"\n",
    "    # Load the original image (for display, not preprocessing)\n",
    "    img = keras_image.load_img(img_path)\n",
    "    img = keras_image.img_to_array(img)\n",
    "\n",
    "    # Resize heatmap to match the original image size\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])) # Use cv2 for convenience\n",
    "\n",
    "    # Apply the heatmap (convert to RGB)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\") # Get colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3] # Use RGB part\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras_image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = keras_image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras_image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained Keras model object\n",
    "# If not loaded, load it: model = tf.keras.models.load_model('your_model.h5')\n",
    "model.summary()\n",
    "# Look for the last Conv2D or similar layer name in the base model part.\n",
    "# For EfficientNetB0, it's often 'top_conv'\n",
    "# For ResNet50, it might be 'conv5_block3_out' or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb26b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grad-CAM Explanation ---\n",
    "\n",
    "# 1. Load your trained model (if not already loaded)\n",
    "# model = tf.keras.models.load_model('path_to_your_model.h5')\n",
    "# OR use the 'model' object if it's still in memory after training\n",
    "\n",
    "# 2. !!! IMPORTANT: Set the name of the last convolutional layer !!!\n",
    "# Use model.summary() to find the correct name for YOUR model architecture\n",
    "LAST_CONV_LAYER_NAME = \"top_conv\" # Example for EfficientNetB0 - CHANGE THIS\n",
    "# LAST_CONV_LAYER_NAME = \"conv5_block3_out\" # Example for ResNet50 - CHANGE THIS\n",
    "\n",
    "# 3. Choose an image to explain\n",
    "img_path = \"/kaggle/input/sem-nffa-europe/data100/Fibres/L9_00fc0a86bd4f02995acdd5b3f63401b9.jpg\" # Replace with an actual image path from your dataset\n",
    "\n",
    "# 4. Preprocess the image for the model\n",
    "img_array = preprocess_image(img_path, target_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]))\n",
    "\n",
    "# 5. Get the model's prediction\n",
    "preds = model.predict(img_array)\n",
    "pred_index = np.argmax(preds[0])\n",
    "pred_class_name = CONFIGURATION[\"CLASS_NAMES\"][pred_index]\n",
    "print(f\"Predicted class: {pred_class_name} (Index: {pred_index}) with confidence {preds[0][pred_index]:.4f}\")\n",
    "\n",
    "# 6. Generate the Grad-CAM heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=pred_index)\n",
    "\n",
    "# 7. Display the heatmap overlaid on the image\n",
    "print(\"Displaying Grad-CAM heatmap...\")\n",
    "display_gradcam(img_path, heatmap, alpha=0.5) # Adjust alpha for heatmap intensity\n",
    "\n",
    "# Optional: Explain a specific class (even if not the top prediction)\n",
    "target_class_index = 1 # e.g., index for \"Nanowires\"\n",
    "target_class_name = CONFIGURATION[\"CLASS_NAMES\"][target_class_index]\n",
    "print(f\"\\nGenerating heatmap for target class: {target_class_name}\")\n",
    "heatmap_target = make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=target_class_index)\n",
    "display_gradcam(img_path, heatmap_target, alpha=0.5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
